{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a926990a-bfb8-4eb6-957b-f28e2ab903b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m712.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921f3bd4-7154-4e50-bb8d-d7e70ef2cb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import required libraries and setup\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eaea2b5-ed9e-4276-9669-1d1446a72361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /home/iceberg/notebooks/data\n",
      "Year to download: 2023\n",
      "Total months to process: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 2: Configuration\n",
    "DATA_PATH = \"/home/iceberg/notebooks/data\"\n",
    "YEAR = \"2023\"\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data\"\n",
    "MONTHS = [f\"{i:02d}\" for i in range(1, 13)]  # 01 through 12\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = Path(DATA_PATH)\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_PATH}\")\n",
    "print(f\"Year to download: {YEAR}\")\n",
    "print(f\"Total months to process: {len(MONTHS)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a6ad37-fc24-4938-a1c0-52cfb48346fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-01.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b71a7f963048d8b9bf5e70ebc50f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-01.parquet:   0%|          | 0.00/45.5M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-02.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0ca734f6474aefb737c4b0fa747b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-02.parquet:   0%|          | 0.00/45.5M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-03.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a6252225c143beb3e95273775b2104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-03.parquet:   0%|          | 0.00/53.5M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-04.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132f2a5e727145d08355b2bd7e593cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-04.parquet:   0%|          | 0.00/51.7M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-05.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213101c26768432a9f41b83ce805b24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-05.parquet:   0%|          | 0.00/55.9M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-06.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2073d569aa2e4081a480698667013fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-06.parquet:   0%|          | 0.00/52.5M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-07.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f36bbf24c84b63931c2f622d917ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-07.parquet:   0%|          | 0.00/46.1M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-08.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bba9cd00c8c4971ab9e1dd1f1d84e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-08.parquet:   0%|          | 0.00/45.9M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-09.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b764f7d4704c2c84314f5fd7737fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-09.parquet:   0%|          | 0.00/45.7M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-10.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523b36a679e74211baaba27a0b00ec5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-10.parquet:   0%|          | 0.00/56.3M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-11.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638fc4171426456fa3d191ab5582d3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-11.parquet:   0%|          | 0.00/53.5M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing yellow_tripdata_2023-12.parquet\n",
      "Downloading from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad25ec566224fb79cc03e65c02a79b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading yellow_tripdata_2023-12.parquet:   0%|          | 0.00/54.2M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download Summary:\n",
      "Month     Status Size (MB) Error\n",
      "   01 Downloaded      45.5  None\n",
      "   02 Downloaded      45.5  None\n",
      "   03 Downloaded      53.5  None\n",
      "   04 Downloaded      51.7  None\n",
      "   05 Downloaded      55.9  None\n",
      "   06 Downloaded      52.5  None\n",
      "   07 Downloaded      46.1  None\n",
      "   08 Downloaded      45.9  None\n",
      "   09 Downloaded      45.7  None\n",
      "   10 Downloaded      56.3  None\n",
      "   11 Downloaded      53.5  None\n",
      "   12 Downloaded      54.2  None\n",
      "\n",
      "Verifying downloaded files:\n",
      "                           File Size (MB)  Status                                                  Error\n",
      "yellow_tripdata_2023-01.parquet      45.5 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-02.parquet      45.5 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-03.parquet      53.5 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-04.parquet      51.7 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-05.parquet      55.9 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-06.parquet      52.5 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-07.parquet      46.1 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-08.parquet      45.9 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-09.parquet      45.7 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-10.parquet      56.3 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-11.parquet      53.5 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "yellow_tripdata_2023-12.parquet      54.2 Invalid read_table() got an unexpected keyword argument 'rows'\n",
      "\n",
      "Total size of downloaded files: 0.59 GB\n",
      "\n",
      "Previewing data from yellow_tripdata_2023-12.parquet\n",
      "\n",
      "Dataset shape: (3376567, 19)\n",
      "\n",
      "Columns: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'Airport_fee']\n",
      "\n",
      "First few rows:\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         1  2023-12-01 00:06:06   2023-12-01 00:15:47              0.0   \n",
      "1         1  2023-12-01 00:22:26   2023-12-01 00:28:53              0.0   \n",
      "2         1  2023-12-01 00:59:44   2023-12-01 01:13:22              2.0   \n",
      "3         2  2023-12-01 00:22:17   2023-12-01 00:30:59              1.0   \n",
      "4         2  2023-12-01 00:18:16   2023-12-01 00:25:32              2.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           1.10         1.0                  N           230            48   \n",
      "1           1.50         1.0                  N           142           238   \n",
      "2           2.20         1.0                  N           114           186   \n",
      "3           0.66         1.0                  N            79            79   \n",
      "4           2.20         1.0                  N           229           263   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1         10.0    3.5      0.5        1.50           0.0   \n",
      "1             1          9.3    3.5      0.5        2.85           0.0   \n",
      "2             1         13.5    3.5      0.5        3.00           0.0   \n",
      "3             2          7.2    1.0      0.5        0.00           0.0   \n",
      "4             1         11.4    1.0      0.5        2.00           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
      "0                    1.0         16.50                   2.5          0.0  \n",
      "1                    1.0         17.15                   2.5          0.0  \n",
      "2                    1.0         21.50                   2.5          0.0  \n",
      "3                    1.0         12.20                   2.5          0.0  \n",
      "4                    1.0         18.40                   2.5          0.0  \n",
      "\n",
      "Data types:\n",
      "VendorID                          int32\n",
      "tpep_pickup_datetime     datetime64[us]\n",
      "tpep_dropoff_datetime    datetime64[us]\n",
      "passenger_count                 float64\n",
      "trip_distance                   float64\n",
      "RatecodeID                      float64\n",
      "store_and_fwd_flag               object\n",
      "PULocationID                      int32\n",
      "DOLocationID                      int32\n",
      "payment_type                      int64\n",
      "fare_amount                     float64\n",
      "extra                           float64\n",
      "mta_tax                         float64\n",
      "tip_amount                      float64\n",
      "tolls_amount                    float64\n",
      "improvement_surcharge           float64\n",
      "total_amount                    float64\n",
      "congestion_surcharge            float64\n",
      "Airport_fee                     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 3: Download function\n",
    "def download_file(url, filepath, description=\"Downloading\"):\n",
    "    \"\"\"Download a file with progress bar\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Get file size for progress bar\n",
    "        file_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        # Show download progress\n",
    "        with filepath.open('wb') as f, tqdm(\n",
    "            desc=description,\n",
    "            total=file_size,\n",
    "            unit='iB',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as pbar:\n",
    "            for data in response.iter_content(chunk_size=8192):\n",
    "                size = f.write(data)\n",
    "                pbar.update(size)\n",
    "                \n",
    "        return True, None\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Cell 4: Download all files\n",
    "download_summary = []\n",
    "\n",
    "for month in MONTHS:\n",
    "    filename = f\"yellow_tripdata_{YEAR}-{month}.parquet\"\n",
    "    filepath = data_dir / filename\n",
    "    url = f\"{BASE_URL}/{filename}\"\n",
    "    \n",
    "    print(f\"\\nProcessing {filename}\")\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if filepath.exists():\n",
    "        size_mb = filepath.stat().st_size / (1024 * 1024)\n",
    "        print(f\"File already exists ({size_mb:.1f} MB), skipping...\")\n",
    "        download_summary.append({\n",
    "            'Month': month,\n",
    "            'Status': 'Exists',\n",
    "            'Size (MB)': f\"{size_mb:.1f}\",\n",
    "            'Error': None\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    # Download file\n",
    "    print(f\"Downloading from {url}\")\n",
    "    success, error = download_file(url, filepath, description=f\"Downloading {filename}\")\n",
    "    \n",
    "    # Record result\n",
    "    if success:\n",
    "        size_mb = filepath.stat().st_size / (1024 * 1024)\n",
    "        download_summary.append({\n",
    "            'Month': month,\n",
    "            'Status': 'Downloaded',\n",
    "            'Size (MB)': f\"{size_mb:.1f}\",\n",
    "            'Error': None\n",
    "        })\n",
    "    else:\n",
    "        download_summary.append({\n",
    "            'Month': month,\n",
    "            'Status': 'Failed',\n",
    "            'Size (MB)': 'N/A',\n",
    "            'Error': error\n",
    "        })\n",
    "\n",
    "# Cell 5: Verify downloads\n",
    "def verify_parquet_files():\n",
    "    \"\"\"Verify all downloaded parquet files\"\"\"\n",
    "    verification_results = []\n",
    "    \n",
    "    files = sorted(data_dir.glob(f\"yellow_tripdata_{YEAR}-*.parquet\"))\n",
    "    \n",
    "    for file in files:\n",
    "        size_mb = file.stat().st_size / (1024 * 1024)\n",
    "        \n",
    "        try:\n",
    "            # Try to read the first row\n",
    "            df = pd.read_parquet(file, rows=1)\n",
    "            status = \"Valid\"\n",
    "            error = None\n",
    "        except Exception as e:\n",
    "            status = \"Invalid\"\n",
    "            error = str(e)\n",
    "        \n",
    "        verification_results.append({\n",
    "            'File': file.name,\n",
    "            'Size (MB)': f\"{size_mb:.1f}\",\n",
    "            'Status': status,\n",
    "            'Error': error\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(verification_results)\n",
    "\n",
    "# Show download summary\n",
    "print(\"\\nDownload Summary:\")\n",
    "download_df = pd.DataFrame(download_summary)\n",
    "print(download_df.to_string(index=False))\n",
    "\n",
    "# Verify files\n",
    "print(\"\\nVerifying downloaded files:\")\n",
    "verification_df = verify_parquet_files()\n",
    "print(verification_df.to_string(index=False))\n",
    "\n",
    "# Show total size\n",
    "total_size_gb = sum(\n",
    "    file.stat().st_size for file in data_dir.glob(f\"yellow_tripdata_{YEAR}-*.parquet\")\n",
    ") / (1024**3)\n",
    "print(f\"\\nTotal size of downloaded files: {total_size_gb:.2f} GB\")\n",
    "\n",
    "# Cell 6: Preview data\n",
    "def preview_data():\n",
    "    \"\"\"Preview the data from a downloaded file\"\"\"\n",
    "    # Try to read the most recent file\n",
    "    files = sorted(data_dir.glob(f\"yellow_tripdata_{YEAR}-*.parquet\"))\n",
    "    if not files:\n",
    "        print(\"No files found to preview\")\n",
    "        return\n",
    "    \n",
    "    latest_file = files[-1]\n",
    "    print(f\"\\nPreviewing data from {latest_file.name}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(latest_file)\n",
    "        print(\"\\nDataset shape:\", df.shape)\n",
    "        print(\"\\nColumns:\", df.columns.tolist())\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "        print(\"\\nData types:\")\n",
    "        print(df.dtypes)\n",
    "    except Exception as e:\n",
    "        print(f\"Error previewing data: {str(e)}\")\n",
    "\n",
    "# Preview the data\n",
    "preview_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
