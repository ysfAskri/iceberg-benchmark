{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9af4020-66cc-43bf-876e-14a2d46c255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install duckdb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a617e8-258a-4ffb-8b9f-ccc1f4df3b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB version: 1.1.3\n",
      "\n",
      "Extensions loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# First cell - Imports and setup\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "from benchmark_utils import BenchmarkResult\n",
    "\n",
    "print(f\"DuckDB version: {duckdb.__version__}\")\n",
    "\n",
    "# Initialize connection and load extensions\n",
    "conn = duckdb.connect()\n",
    "conn.execute(\"INSTALL httpfs;\")\n",
    "conn.execute(\"LOAD httpfs;\")\n",
    "conn.execute(\"INSTALL iceberg;\")\n",
    "conn.execute(\"LOAD iceberg;\")\n",
    "\n",
    "print(\"\\nExtensions loaded successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2684e26-b35f-48fc-a29d-a9012397c65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3/MinIO configurations set.\n"
     ]
    }
   ],
   "source": [
    "# Second cell - Configure S3/MinIO settings\n",
    "def configure_s3(conn, access_key=\"admin\", secret_key=\"password\", \n",
    "                endpoint=\"minio:9000\", region=\"us-east-1\", use_ssl=False):\n",
    "    conn.execute(f\"\"\"\n",
    "    SET s3_region='{region}';\n",
    "    SET s3_access_key_id='{access_key}';\n",
    "    SET s3_secret_access_key='{secret_key}';\n",
    "    SET s3_endpoint='{endpoint}';\n",
    "    SET s3_use_ssl={str(use_ssl).lower()};\n",
    "    \"\"\")\n",
    "    print(\"S3/MinIO configurations set.\")\n",
    "\n",
    "# Configure S3\n",
    "configure_s3(conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1715163d-3fc2-4251-b9d7-513cf90cdac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Third cell - Function to find latest metadata file\n",
    "def find_latest_metadata(conn, iceberg_table_path):\n",
    "    \"\"\"Find the latest metadata file for an Iceberg table\"\"\"\n",
    "    try:\n",
    "        # List all metadata files\n",
    "        print(\"Searching for metadata files...\")\n",
    "        metadata_files = conn.execute(f\"\"\"\n",
    "            SELECT *\n",
    "            FROM glob('{iceberg_table_path}/metadata/*.json')\n",
    "            ORDER BY file DESC\n",
    "        \"\"\").fetchdf()\n",
    "        \n",
    "        if metadata_files.empty:\n",
    "            raise Exception(\"No metadata files found\")\n",
    "        \n",
    "        print(f\"\\nFound {len(metadata_files)} metadata files:\")\n",
    "        print(metadata_files)\n",
    "        \n",
    "        # Extract metadata file numbers\n",
    "        def extract_number(filename):\n",
    "            match = re.search(r'/(\\d{5})-', filename)\n",
    "            return int(match.group(1)) if match else -1\n",
    "        \n",
    "        metadata_files['number'] = metadata_files['file'].apply(extract_number)\n",
    "        latest_metadata = metadata_files.loc[metadata_files['number'].idxmax(), 'file']\n",
    "        \n",
    "        print(f\"\\nLatest metadata file: {latest_metadata}\")\n",
    "        return latest_metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error finding latest metadata: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ef8a05e-615e-4a03-adae-905abd3c4042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for metadata files...\n",
      "\n",
      "Found 39 metadata files:\n",
      "                                                 file\n",
      "0   s3://warehouse/nyc/taxis/metadata/00024-41849b...\n",
      "1   s3://warehouse/nyc/taxis/metadata/00023-9258d4...\n",
      "2   s3://warehouse/nyc/taxis/metadata/00022-6d3ab8...\n",
      "3   s3://warehouse/nyc/taxis/metadata/00021-b58fd1...\n",
      "4   s3://warehouse/nyc/taxis/metadata/00020-d39091...\n",
      "5   s3://warehouse/nyc/taxis/metadata/00019-853d76...\n",
      "6   s3://warehouse/nyc/taxis/metadata/00018-886824...\n",
      "7   s3://warehouse/nyc/taxis/metadata/00017-43b584...\n",
      "8   s3://warehouse/nyc/taxis/metadata/00016-71338f...\n",
      "9   s3://warehouse/nyc/taxis/metadata/00015-fd607c...\n",
      "10  s3://warehouse/nyc/taxis/metadata/00014-dd3476...\n",
      "11  s3://warehouse/nyc/taxis/metadata/00013-0f0a0a...\n",
      "12  s3://warehouse/nyc/taxis/metadata/00012-582c06...\n",
      "13  s3://warehouse/nyc/taxis/metadata/00012-4c4b3a...\n",
      "14  s3://warehouse/nyc/taxis/metadata/00011-d66f07...\n",
      "15  s3://warehouse/nyc/taxis/metadata/00011-ca8992...\n",
      "16  s3://warehouse/nyc/taxis/metadata/00010-332fea...\n",
      "17  s3://warehouse/nyc/taxis/metadata/00010-04da42...\n",
      "18  s3://warehouse/nyc/taxis/metadata/00009-d05a06...\n",
      "19  s3://warehouse/nyc/taxis/metadata/00009-04ba07...\n",
      "20  s3://warehouse/nyc/taxis/metadata/00008-9afcef...\n",
      "21  s3://warehouse/nyc/taxis/metadata/00008-5b17e2...\n",
      "22  s3://warehouse/nyc/taxis/metadata/00007-c0f86b...\n",
      "23  s3://warehouse/nyc/taxis/metadata/00007-1e35d7...\n",
      "24  s3://warehouse/nyc/taxis/metadata/00006-70cc2d...\n",
      "25  s3://warehouse/nyc/taxis/metadata/00006-4b5763...\n",
      "26  s3://warehouse/nyc/taxis/metadata/00005-86e044...\n",
      "27  s3://warehouse/nyc/taxis/metadata/00005-4881c7...\n",
      "28  s3://warehouse/nyc/taxis/metadata/00004-96bd8a...\n",
      "29  s3://warehouse/nyc/taxis/metadata/00004-36e165...\n",
      "30  s3://warehouse/nyc/taxis/metadata/00003-fa5b58...\n",
      "31  s3://warehouse/nyc/taxis/metadata/00003-2e5113...\n",
      "32  s3://warehouse/nyc/taxis/metadata/00002-ea1130...\n",
      "33  s3://warehouse/nyc/taxis/metadata/00002-b91899...\n",
      "34  s3://warehouse/nyc/taxis/metadata/00001-fa05c0...\n",
      "35  s3://warehouse/nyc/taxis/metadata/00001-7e0536...\n",
      "36  s3://warehouse/nyc/taxis/metadata/00000-983ee0...\n",
      "37  s3://warehouse/nyc/taxis/metadata/00000-7eb617...\n",
      "38  s3://warehouse/nyc/taxis/metadata/00000-09068e...\n",
      "\n",
      "Latest metadata file: s3://warehouse/nyc/taxis/metadata/00024-41849b29-2da8-432a-9f14-0acee4f595b0.metadata.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fourth cell - Find latest metadata for your table\n",
    "iceberg_table_path = \"s3://warehouse/nyc/taxis\"\n",
    "latest_metadata = find_latest_metadata(conn, iceberg_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d21ec544-2948-4df5-9a84-02731eead3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing simple aggregation query...\n",
      "\n",
      "Query:\n",
      "\n",
      "        SELECT\n",
      "            COUNT(*) AS total_records,\n",
      "            AVG(trip_distance) AS avg_trip_distance,\n",
      "            MAX(total_amount) AS max_total_amount,\n",
      "            MIN(fare_amount) AS min_fare_amount\n",
      "        FROM iceberg_scan('s3://warehouse/nyc/taxis/metadata/00024-41849b29-2da8-432a-9f14-0acee4f595b0.metadata.json')\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9fcc7fa9d2471880e5fd359576d391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query completed in 4.42 seconds\n",
      "\n",
      "Results:\n",
      "   total_records  avg_trip_distance  max_total_amount  min_fare_amount\n",
      "0       77966324           5.040317         401095.62     -133391414.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 4: Run simple query\n",
    "def run_simple_query(conn, metadata_file):\n",
    "    \"\"\"Run and time a simple aggregation query\"\"\"\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "            COUNT(*) AS total_records,\n",
    "            AVG(trip_distance) AS avg_trip_distance,\n",
    "            MAX(total_amount) AS max_total_amount,\n",
    "            MIN(fare_amount) AS min_fare_amount\n",
    "        FROM iceberg_scan('{metadata_file}')\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Executing simple aggregation query...\")\n",
    "    print(\"\\nQuery:\")\n",
    "    print(query.format(metadata_file=metadata_file))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = conn.execute(query.format(metadata_file=metadata_file)).fetchdf()\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nQuery completed in {duration:.2f} seconds\")\n",
    "    print(\"\\nResults:\")\n",
    "    print(result)\n",
    "    \n",
    "    return {\"duration\": duration, \"result\": result}\n",
    "\n",
    "# Run simple query\n",
    "simple_results = run_simple_query(conn, latest_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c09d11e8-88c3-4293-85ac-e69d5435dcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing complex analysis query...\n",
      "\n",
      "Query:\n",
      "\n",
      "        SELECT\n",
      "            payment_type,\n",
      "            COUNT(*) AS trip_count,\n",
      "            AVG(total_amount) AS avg_total_amount,\n",
      "            MAX(tip_amount) AS max_tip_amount,\n",
      "            SUM(CASE WHEN passenger_count > 1 THEN 1 ELSE 0 END) as shared_rides\n",
      "        FROM iceberg_scan('s3://warehouse/nyc/taxis/metadata/00024-41849b29-2da8-432a-9f14-0acee4f595b0.metadata.json')\n",
      "        WHERE trip_distance > 2 AND total_amount > 0\n",
      "        GROUP BY payment_type\n",
      "        ORDER BY trip_count DESC\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa11deabe674682aff42fc55dc12d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query completed in 6.99 seconds\n",
      "\n",
      "Results:\n",
      "   payment_type  trip_count  avg_total_amount  max_tip_amount  shared_rides\n",
      "0             1    27504582         37.871267         1400.16     6696053.0\n",
      "1             2     5922309         33.125444           32.00     1745599.0\n",
      "2             0     1603076         35.306151           92.35           0.0\n",
      "3             4      134663         42.777958           95.00       32343.0\n",
      "4             3       90810         33.755191           90.00       20430.0\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Run complex query\n",
    "def run_complex_query(conn, metadata_file):\n",
    "    \"\"\"Run and time a complex analysis query\"\"\"\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "            payment_type,\n",
    "            COUNT(*) AS trip_count,\n",
    "            AVG(total_amount) AS avg_total_amount,\n",
    "            MAX(tip_amount) AS max_tip_amount,\n",
    "            SUM(CASE WHEN passenger_count > 1 THEN 1 ELSE 0 END) as shared_rides\n",
    "        FROM iceberg_scan('{metadata_file}')\n",
    "        WHERE trip_distance > 2 AND total_amount > 0\n",
    "        GROUP BY payment_type\n",
    "        ORDER BY trip_count DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Executing complex analysis query...\")\n",
    "    print(\"\\nQuery:\")\n",
    "    print(query.format(metadata_file=metadata_file))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = conn.execute(query.format(metadata_file=metadata_file)).fetchdf()\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nQuery completed in {duration:.2f} seconds\")\n",
    "    print(\"\\nResults:\")\n",
    "    print(result)\n",
    "    \n",
    "    return {\"duration\": duration, \"result\": result}\n",
    "\n",
    "# Run complex query\n",
    "complex_results = run_complex_query(conn, latest_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4a4c46-a42f-4ec8-8b37-f5570beb388f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing advanced fare trend analysis (DuckDB)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c760e4f91b084af19224843ab9c189f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis completed in 13.01 seconds\n",
      "Total records analyzed: 125\n",
      "\n",
      "Results preview (most recent month):\n",
      "                      month  payment_type  avg_base_fare  avg_total_fare  \\\n",
      "0 2024-01-01 00:00:00+00:00             1          72.96           85.72   \n",
      "1 2024-01-01 00:00:00+00:00             2           6.50           11.50   \n",
      "2 2023-12-01 00:00:00+00:00             0          22.90           28.99   \n",
      "3 2023-12-01 00:00:00+00:00             1          20.02           30.12   \n",
      "4 2023-12-01 00:00:00+00:00             2          20.10           25.41   \n",
      "\n",
      "   interpolated_tip  num_rides  fare_stddev  fare_change  fare_change_pct  \\\n",
      "0              8.67          5        40.06        52.94            264.4   \n",
      "1              0.00          1          NaN       -13.60            -67.7   \n",
      "2              1.77     176966        14.13         1.11              5.1   \n",
      "3              4.49    2574324        17.90        -0.04             -0.2   \n",
      "4              0.00     536489        19.89         0.11              0.6   \n",
      "\n",
      "    trend_category  \n",
      "0  Strong Increase  \n",
      "1  Strong Decrease  \n",
      "2  Strong Increase  \n",
      "3           Stable  \n",
      "4           Stable  \n",
      "\n",
      "Summary Statistics:\n",
      "Average base fare: $19.49\n",
      "Average total fare: $25.46\n",
      "Average tip: $1.47\n",
      "\n",
      "Trend Distribution:\n",
      "trend_category\n",
      "Moderate Increase    39\n",
      "Strong Increase      27\n",
      "Moderate Decrease    24\n",
      "Stable               19\n",
      "Strong Decrease      16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def run_advanced_analysis_duckdb(conn, metadata_file):\n",
    "    \"\"\"Run advanced fare analysis with trend detection and interpolation for DuckDB\n",
    "    \n",
    "    Args:\n",
    "        conn: DuckDB connection\n",
    "        metadata_file: Path to Iceberg metadata file\n",
    "    Returns:\n",
    "        dict: Contains duration and results dataframe\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    WITH fare_stats AS (\n",
    "        SELECT \n",
    "            date_trunc('month', tpep_pickup_datetime) as month,\n",
    "            payment_type,\n",
    "            AVG(fare_amount) as avg_base_fare,\n",
    "            AVG(total_amount) as avg_total_fare,\n",
    "            AVG(tip_amount) as avg_tip,\n",
    "            COUNT(*) as num_rides,\n",
    "            STDDEV(fare_amount) as fare_stddev\n",
    "        FROM iceberg_scan('{metadata_file}')\n",
    "        WHERE fare_amount > 0 \n",
    "        AND total_amount > 0\n",
    "        AND EXTRACT(year FROM tpep_pickup_datetime) >= 2022\n",
    "        GROUP BY \n",
    "            date_trunc('month', tpep_pickup_datetime),\n",
    "            payment_type\n",
    "    ),\n",
    "    interpolated_points AS (\n",
    "        SELECT \n",
    "            month,\n",
    "            payment_type,\n",
    "            avg_base_fare,\n",
    "            avg_total_fare,\n",
    "            CASE \n",
    "                WHEN avg_tip IS NULL THEN \n",
    "                    LAG(avg_tip, 1) OVER (PARTITION BY payment_type ORDER BY month) +\n",
    "                    (LEAD(avg_tip, 1) OVER (PARTITION BY payment_type ORDER BY month) -\n",
    "                     LAG(avg_tip, 1) OVER (PARTITION BY payment_type ORDER BY month)) * 0.5\n",
    "                ELSE avg_tip\n",
    "            END as interpolated_tip,\n",
    "            num_rides,\n",
    "            fare_stddev,\n",
    "            avg_base_fare - LAG(avg_base_fare) OVER (PARTITION BY payment_type ORDER BY month) as fare_change,\n",
    "            100.0 * (avg_base_fare - LAG(avg_base_fare) OVER (PARTITION BY payment_type ORDER BY month)) / \n",
    "                NULLIF(LAG(avg_base_fare) OVER (PARTITION BY payment_type ORDER BY month), 0) as fare_change_pct\n",
    "        FROM fare_stats\n",
    "    )\n",
    "    SELECT \n",
    "        month,\n",
    "        payment_type,\n",
    "        ROUND(avg_base_fare, 2) as avg_base_fare,\n",
    "        ROUND(avg_total_fare, 2) as avg_total_fare,\n",
    "        ROUND(interpolated_tip, 2) as interpolated_tip,\n",
    "        num_rides,\n",
    "        ROUND(fare_stddev, 2) as fare_stddev,\n",
    "        ROUND(fare_change, 2) as fare_change,\n",
    "        ROUND(fare_change_pct, 1) as fare_change_pct,\n",
    "        CASE \n",
    "            WHEN fare_change_pct > 5 THEN 'Strong Increase'\n",
    "            WHEN fare_change_pct BETWEEN 1 AND 5 THEN 'Moderate Increase'\n",
    "            WHEN fare_change_pct BETWEEN -1 AND 1 THEN 'Stable'\n",
    "            WHEN fare_change_pct BETWEEN -5 AND -1 THEN 'Moderate Decrease'\n",
    "            ELSE 'Strong Decrease'\n",
    "        END as trend_category\n",
    "    FROM interpolated_points\n",
    "    ORDER BY month DESC, payment_type;\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Executing advanced fare trend analysis (DuckDB)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        result = conn.execute(query.format(metadata_file=metadata_file)).fetchdf()\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nAnalysis completed in {duration:.2f} seconds\")\n",
    "        print(f\"Total records analyzed: {len(result):,}\")\n",
    "        print(\"\\nResults preview (most recent month):\")\n",
    "        print(result.head())\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        print(\"\\nSummary Statistics:\")\n",
    "        print(f\"Average base fare: ${result['avg_base_fare'].mean():.2f}\")\n",
    "        print(f\"Average total fare: ${result['avg_total_fare'].mean():.2f}\")\n",
    "        print(f\"Average tip: ${result['interpolated_tip'].mean():.2f}\")\n",
    "        print(\"\\nTrend Distribution:\")\n",
    "        print(result['trend_category'].value_counts())\n",
    "        \n",
    "        return {\"duration\": duration, \"result\": result}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error executing DuckDB analysis: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Run advanced analysis\n",
    "advanced_results = run_advanced_analysis_duckdb(conn, latest_metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ee98067-6413-46fd-a2ed-df2635968a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'duration': 13.014678716659546, 'result':                         month  payment_type  avg_base_fare  avg_total_fare  \\\n",
      "0   2024-01-01 00:00:00+00:00             1          72.96           85.72   \n",
      "1   2024-01-01 00:00:00+00:00             2           6.50           11.50   \n",
      "2   2023-12-01 00:00:00+00:00             0          22.90           28.99   \n",
      "3   2023-12-01 00:00:00+00:00             1          20.02           30.12   \n",
      "4   2023-12-01 00:00:00+00:00             2          20.10           25.41   \n",
      "..                        ...           ...            ...             ...   \n",
      "120 2022-01-01 00:00:00+00:00             1          12.77           19.73   \n",
      "121 2022-01-01 00:00:00+00:00             2          12.83           16.53   \n",
      "122 2022-01-01 00:00:00+00:00             3          11.97           15.45   \n",
      "123 2022-01-01 00:00:00+00:00             4         138.37          141.96   \n",
      "124 2022-01-01 00:00:00+00:00             5           8.50           11.80   \n",
      "\n",
      "     interpolated_tip  num_rides  fare_stddev  fare_change  fare_change_pct  \\\n",
      "0                8.67          5        40.06        52.94            264.4   \n",
      "1                0.00          1          NaN       -13.60            -67.7   \n",
      "2                1.77     176966        14.13         1.11              5.1   \n",
      "3                4.49    2574324        17.90        -0.04             -0.2   \n",
      "4                0.00     536489        19.89         0.11              0.6   \n",
      "..                ...        ...          ...          ...              ...   \n",
      "120              3.02    1874492        11.97          NaN              NaN   \n",
      "121              0.00     492515        12.87          NaN              NaN   \n",
      "122              0.00       8357        14.67          NaN              NaN   \n",
      "123              0.00       3185      7106.85          NaN              NaN   \n",
      "124              0.00          1          NaN          NaN              NaN   \n",
      "\n",
      "      trend_category  \n",
      "0    Strong Increase  \n",
      "1    Strong Decrease  \n",
      "2    Strong Increase  \n",
      "3             Stable  \n",
      "4             Stable  \n",
      "..               ...  \n",
      "120  Strong Decrease  \n",
      "121  Strong Decrease  \n",
      "122  Strong Decrease  \n",
      "123  Strong Decrease  \n",
      "124  Strong Decrease  \n",
      "\n",
      "[125 rows x 10 columns]}\n"
     ]
    }
   ],
   "source": [
    "print(advanced_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f82f6cc6-4fcf-459a-b185-3f660830020a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark results saved to duckdb_benchmark_results.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Save benchmark results\n",
    "result = BenchmarkResult(\"DuckDB\", duckdb.__version__)\n",
    "\n",
    "# For simple query:\n",
    "total_records = simple_results[\"result\"][\"total_records\"].iloc[0]  # Get the COUNT(*) result\n",
    "result.add_query_result(\n",
    "    \"simple_aggregation\",\n",
    "    simple_results[\"duration\"],\n",
    "    total_records,\n",
    "    simple_results[\"result\"]\n",
    ")\n",
    "\n",
    "# For complex query:\n",
    "total_records = complex_results[\"result\"][\"trip_count\"].sum()  # Sum all group counts\n",
    "result.add_query_result(\n",
    "    \"complex_analysis\",\n",
    "    complex_results[\"duration\"],\n",
    "    total_records,\n",
    "    complex_results[\"result\"]\n",
    ")\n",
    "\n",
    "result.add_query_result(\n",
    "    \"advanced_analysis\",\n",
    "    advanced_results[\"duration\"],\n",
    "    advanced_results[\"result\"][\"num_rides\"].sum(),\n",
    "    advanced_results[\"result\"]\n",
    ")\n",
    "\n",
    "# Save results (automatically captures resource usage)\n",
    "result.save('duckdb_benchmark_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c320600f-2c33-45ca-b7af-cfd5d7d6a235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DuckDB connection closed\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Clean up\n",
    "conn.close()\n",
    "print(\"\\nDuckDB connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad766153-5f1b-44c4-9e1d-0f534dbbb396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
